{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "43c38433-6d17-4b1e-9f2a-bca4f692489a",
    "_execution_state": "idle",
    "_uuid": "ea7d07e39f8c6160c05767de0c4f7f6489ebe8df"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramona/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ramona/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/home/ramona/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/home/ramona/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn import *\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "from Read_data import read_data\n",
    "from evaluation import evaluation_class\n",
    "import ourPreprocessor\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training data (included stage1 test data set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class  \\\n",
       "0   0  FAM58A  Truncating Mutations      1   \n",
       "1   1     CBL                 W802*      2   \n",
       "2   2     CBL                 Q249E      2   \n",
       "3   3     CBL                 N454D      3   \n",
       "4   4     CBL                 L399V      4   \n",
       "\n",
       "                                                Text  \n",
       "0  Cyclin-dependent kinases (CDKs) regulate a var...  \n",
       "1   Abstract Background  Non-small cell lung canc...  \n",
       "2   Abstract Background  Non-small cell lung canc...  \n",
       "3  Recent evidence has demonstrated that acquired...  \n",
       "4  Oncogenic mutations in the monomeric Casitas B...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../utils/data/training_variants\")\n",
    "trainx = pd.read_csv('../utils/data/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "train_merge_df = pd.merge(train, trainx, how='left', on='ID')\n",
    "train_merge_df = train_merge_df.loc[~train_merge_df.Text.isnull()]\n",
    "print(train_merge_df.shape)\n",
    "train_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3683, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Gene</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>0</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>W802*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>Q249E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "      <td>N454D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "      <td>L399V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class    Gene  ID                                               Text  \\\n",
       "0      1  FAM58A   0  Cyclin-dependent kinases (CDKs) regulate a var...   \n",
       "1      2     CBL   1   Abstract Background  Non-small cell lung canc...   \n",
       "2      2     CBL   2   Abstract Background  Non-small cell lung canc...   \n",
       "3      3     CBL   3  Recent evidence has demonstrated that acquired...   \n",
       "4      4     CBL   4  Oncogenic mutations in the monomeric Casitas B...   \n",
       "\n",
       "              Variation  \n",
       "0  Truncating Mutations  \n",
       "1                 W802*  \n",
       "2                 Q249E  \n",
       "3                 N454D  \n",
       "4                 L399V  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load stage1 test files\n",
    "test = pd.read_csv(\"../utils/data/test_variants.csv\")\n",
    "testx = pd.read_csv(\"../utils/data/test_text.csv\", sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])\n",
    "solution = pd.read_csv(\"../utils/data/solution_filtered.csv\")\n",
    "test_merge_df = test.merge(testx,left_on=\"ID\",right_on=\"ID\")\n",
    "\n",
    "#add the classification to the test_merge\n",
    "solution.columns = ['ID', 1, 2, 3, 4, 5, 6,\n",
    "       7, 8, 9]\n",
    "Class_df = pd.DataFrame()\n",
    "Class_df['ID'] = solution['ID']\n",
    "Class_df['Class'] =  solution[[1, 2, 3, 4, 5, 6,\n",
    "       7, 8, 9]].idxmax(axis=1)\n",
    "test_classified_df = test_merge_df.merge(Class_df,left_on=\"ID\",right_on=\"ID\")\n",
    "test_classified_df = test_classified_df.loc[~test_classified_df.Text.isnull()] #delete samples with NaN as text\n",
    "train = train_merge_df.append(test_classified_df)\n",
    "print(train.shape)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data (stage2 test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>RNF6</td>\n",
       "      <td>G244D</td>\n",
       "      <td>Human ESCCs 2 occur frequently worldwide (1) ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>ERBB2</td>\n",
       "      <td>G746S</td>\n",
       "      <td>The protein-kinase family is the most frequent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>TP53</td>\n",
       "      <td>Y234S</td>\n",
       "      <td>Among the best-studied therapeutic targets in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>P546S</td>\n",
       "      <td>Head and neck squamous cell carcinoma (HNSCC) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>ERBB2</td>\n",
       "      <td>G279E</td>\n",
       "      <td>Functional characterization of cancer-associat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Gene Variation                                               Text\n",
       "0   8   RNF6     G244D  Human ESCCs 2 occur frequently worldwide (1) ....\n",
       "1  15  ERBB2     G746S  The protein-kinase family is the most frequent...\n",
       "2  16   TP53     Y234S  Among the best-studied therapeutic targets in ...\n",
       "3  18   EGFR     P546S  Head and neck squamous cell carcinoma (HNSCC) ...\n",
       "4  19  ERBB2     G279E  Functional characterization of cancer-associat..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_testx = pd.read_csv('../utils/stage2_data/stage2_test_text.csv', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "stage2_test = pd.read_csv('/mnt/4_TB_HD/ramona/utils/stage2_data/stage2_test_variants.csv')\n",
    "stage2_solution = pd.read_csv('../utils/stage2_data/stage_2_private_solution.csv')\n",
    "stage2_merge_df= pd.merge(stage2_test, stage2_testx, how='left', on='ID').fillna('')\n",
    "\n",
    "#transform classification and take only those stage 2 samples with solution (125 out of 986)\n",
    "stage2_solution.columns = ['ID', 1, 2, 3, 4, 5, 6,\n",
    "       7, 8, 9]\n",
    "stage2_Class_df = pd.DataFrame()\n",
    "stage2_Class_df['ID'] = stage2_solution['ID']\n",
    "stage2_Class_df['Class'] = stage2_solution[[1, 2, 3, 4, 5, 6,\n",
    "       7, 8, 9]].idxmax(axis=1)\n",
    "\n",
    "stage2_classified_df = stage2_merge_df.merge(stage2_Class_df,left_on=\"ID\",right_on=\"ID\")\n",
    "y_test = stage2_classified_df['Class'].values\n",
    "stage2 = stage2_classified_df.drop(['Class'], axis=1)\n",
    "print(stage2.shape)\n",
    "stage2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification for test and train\n",
    "y = np.append(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3573\n",
      "3392\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat((train, stage2), axis=0, ignore_index=True)\n",
    "df_all['Gene_Share'] = df_all.apply(lambda r: sum([1 for w in r['Gene'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n",
    "df_all['Variation_Share'] = df_all.apply(lambda r: sum([1 for w in r['Variation'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n",
    "\n",
    "gen_var_lst = sorted(list(train.Gene.unique()) + list(train.Variation.unique()))\n",
    "print(len(gen_var_lst))\n",
    "gen_var_lst = [x for x in gen_var_lst if len(x.split(' '))==1]\n",
    "print(len(gen_var_lst))\n",
    "i_ = 0\n",
    "\n",
    "for c in df_all.columns:\n",
    "    if df_all[c].dtype == 'object':\n",
    "        if c in ['Gene','Variation']:\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            df_all[c+'_lbl_enc'] = lbl.fit_transform(df_all[c].values)  \n",
    "            df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n",
    "            df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' ')))\n",
    "        elif c != 'Text':\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            df_all[c] = lbl.fit_transform(df_all[c].values)\n",
    "        if c=='Text': \n",
    "            df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n",
    "            df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' '))) \n",
    "\n",
    "class cust_regression_vals(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        x = x.drop(['Gene', 'Variation','ID','Text'],axis=1).values\n",
    "        return x\n",
    "\n",
    "class cust_txt_col(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        return x[self.key].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new train and text set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3683, 14)\n",
      "(125, 14)\n"
     ]
    }
   ],
   "source": [
    "# determine length of train set\n",
    "length_of_train = len(train)\n",
    "\n",
    "# shuffle data set\n",
    "df_all['Class'] = y\n",
    "df_all = df_all.sample(frac=1)\n",
    "y_train_shuffled = df_all['Class'].iloc[:length_of_train]\n",
    "y_test_shuffled = df_all['Class'].iloc[length_of_train:]\n",
    "df_all = df_all.drop(['Class'], axis=1)\n",
    "    \n",
    "train = df_all.iloc[:length_of_train]; print(train.shape)  \n",
    "test = df_all.iloc[slength_of_train:]; print(test.shape)\n",
    "\n",
    "size = 3808-length_of_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline...\n"
     ]
    }
   ],
   "source": [
    "print('Pipeline...')\n",
    "fp = pipeline.Pipeline([\n",
    "    ('union', pipeline.FeatureUnion(\n",
    "        n_jobs = 1,\n",
    "        transformer_list = [\n",
    "            ('standard', cust_regression_vals()),\n",
    "            ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd1', decomposition.TruncatedSVD(n_components=25, n_iter=25, random_state=12))])),\n",
    "            ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd2', decomposition.TruncatedSVD(n_components=25, n_iter=25, random_state=12))])),\n",
    "\n",
    "            ('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), ('tfidf_Text', feature_extraction.text.TfidfVectorizer(preprocessor=ourPreprocessor.myPreprocessor, tokenizer=ourPreprocessor.myTokenizer, ngram_range=(1,3), stop_words=ourPreprocessor.stopWords)), ('tsvd3', decomposition.TruncatedSVD(n_components=300, n_iter=25, random_state=12))]))\n",
    "        ])\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3683, 14)\n",
      "(125, 14)\n"
     ]
    }
   ],
   "source": [
    "train_transformed = fp.fit_transform(train); print(train.shape)\n",
    "test_transformed = fp.transform(test); print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18-05-30-13-08'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pipeline( model=None, time=None):\n",
    "    pickle.dump(fp, open('/mnt/4_TB_HD/ramona/utils/textPipelines/featurepipeline_'+time+'.pkl', 'wb'))\n",
    "    \n",
    "def save_pipelineinfo( model = '' , trainpickle = '', testpickle= '', Y_train='', Y_test='', balance = '', genecolumns='', shuffled = '', svd_name = '', pipeline_date =''):\n",
    "    filename = '/mnt/4_TB_HD/ramona/deliver/pipelineinfo2.csv'\n",
    "    with open(filename,'a') as f:\n",
    "        f = csv.writer(f)\n",
    "        f.writerow([ model, trainpickle, testpickle, Y_train, Y_test, 'full' ,balance,shuffled, genecolumns, svd_name, pipeline_date, 'testset size is'+ size  ])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/4_TB_HD/ramona/utils/features/'\n",
    "filename1 = 'Xtrain_' + time\n",
    "filename2 = 'Xtest_' + time\n",
    "filename3 =  'Ytrain_' + time \n",
    "filename4 =  'Ytest_' + time \n",
    "with open(path + filename1, 'wb') as f1:\n",
    "    pickle.dump(train_transformed, f1)\n",
    "with open(path + filename2, 'wb') as f2:\n",
    "    pickle.dump(test_transformed ,f2)\n",
    "with open(path + filename3, 'wb') as f2:\n",
    "    pickle.dump(y_train_shuffled.values ,f2)\n",
    "with open(path + filename4, 'wb') as f2:\n",
    "    pickle.dump(y_test_shuffled.values ,f2)\n",
    "\n",
    "\n",
    "filename5 = 'train_before_pipeline' + time\n",
    "filename6 = 'test_before_pipeline' + time\n",
    "with open(path + filename5, 'wb') as f1:\n",
    "    pickle.dump(train, f1)\n",
    "with open(path + filename6, 'wb') as f2:\n",
    "    pickle.dump(test ,f2)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cbb47fb264d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msave_pipelineinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'union'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'union'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'union'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'union'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbalance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-169325ee6d92>\u001b[0m in \u001b[0;36msave_pipelineinfo\u001b[0;34m(model, trainpickle, testpickle, Y_train, Y_test, balance, genecolumns, shuffled, svd_name, pipeline_date)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainpickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestpickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'full'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbalance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenecolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'testset size is'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not int"
     ]
    }
   ],
   "source": [
    "\n",
    "save_pipelineinfo([fp.named_steps['union'].transformer_list[0], fp.named_steps['union'].transformer_list[1][1].named_steps, fp.named_steps['union'].transformer_list[2][1].named_steps, fp.named_steps['union'].transformer_list[3][1].named_steps], filename1, filename2, filename3, filename4, shuffled = True,  balance = '', pipeline_date=time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pipeline(fp, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open('/mnt/4_TB_HD/ramona/utils/textPipelines/featurepipeline_'+time+'.pkl', 'rb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.named_steps['union'].transformer_list[3][1].named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
