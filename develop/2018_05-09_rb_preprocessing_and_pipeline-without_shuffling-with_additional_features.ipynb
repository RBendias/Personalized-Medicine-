{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "43c38433-6d17-4b1e-9f2a-bca4f692489a",
    "_execution_state": "idle",
    "_uuid": "ea7d07e39f8c6160c05767de0c4f7f6489ebe8df"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramona/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ramona/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/home/ramona/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/home/ramona/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn import *\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "from Read_data import read_data\n",
    "from evaluation import evaluation_class\n",
    "import ourPreprocessor\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training data (included stage1 test data set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class  \\\n",
       "0   0  FAM58A  Truncating Mutations      1   \n",
       "1   1     CBL                 W802*      2   \n",
       "2   2     CBL                 Q249E      2   \n",
       "3   3     CBL                 N454D      3   \n",
       "4   4     CBL                 L399V      4   \n",
       "\n",
       "                                                Text  \n",
       "0  Cyclin-dependent kinases (CDKs) regulate a var...  \n",
       "1   Abstract Background  Non-small cell lung canc...  \n",
       "2   Abstract Background  Non-small cell lung canc...  \n",
       "3  Recent evidence has demonstrated that acquired...  \n",
       "4  Oncogenic mutations in the monomeric Casitas B...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../utils/data/training_variants\")\n",
    "trainx = pd.read_csv('../utils/data/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "train_merge_df = pd.merge(train, trainx, how='left', on='ID')\n",
    "train_merge_df = train_merge_df.loc[~train_merge_df.Text.isnull()]\n",
    "print(train_merge_df.shape)\n",
    "train_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3683, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Gene</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>0</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>W802*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>Q249E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "      <td>N454D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "      <td>L399V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class    Gene  ID                                               Text  \\\n",
       "0      1  FAM58A   0  Cyclin-dependent kinases (CDKs) regulate a var...   \n",
       "1      2     CBL   1   Abstract Background  Non-small cell lung canc...   \n",
       "2      2     CBL   2   Abstract Background  Non-small cell lung canc...   \n",
       "3      3     CBL   3  Recent evidence has demonstrated that acquired...   \n",
       "4      4     CBL   4  Oncogenic mutations in the monomeric Casitas B...   \n",
       "\n",
       "              Variation  \n",
       "0  Truncating Mutations  \n",
       "1                 W802*  \n",
       "2                 Q249E  \n",
       "3                 N454D  \n",
       "4                 L399V  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load stage1 test files\n",
    "test = pd.read_csv(\"../utils/data/test_variants.csv\")\n",
    "testx = pd.read_csv(\"../utils/data/test_text.csv\", sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])\n",
    "solution = pd.read_csv(\"../utils/data/solution_filtered.csv\")\n",
    "test_merge_df = test.merge(testx,left_on=\"ID\",right_on=\"ID\")\n",
    "\n",
    "#add the classification to the test_merge\n",
    "solution.columns = ['ID', 1, 2, 3, 4, 5, 6,\n",
    "       7, 8, 9]\n",
    "Class_df = pd.DataFrame()\n",
    "Class_df['ID'] = solution['ID']\n",
    "Class_df['Class'] =  solution[[1, 2, 3, 4, 5, 6,\n",
    "       7, 8, 9]].idxmax(axis=1)\n",
    "test_classified_df = test_merge_df.merge(Class_df,left_on=\"ID\",right_on=\"ID\")\n",
    "test_classified_df = test_classified_df.loc[~test_classified_df.Text.isnull()] #delete samples with NaN as text\n",
    "train = train_merge_df.append(test_classified_df)\n",
    "print(train.shape)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Class'].values\n",
    "train = train.drop(['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data (stage2 test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CHEK2</td>\n",
       "      <td>H371Y</td>\n",
       "      <td>The incidence of breast cancer is increasing i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AXIN2</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>An unselected series of 310 colorectal carcino...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WNT4</td>\n",
       "      <td>E216G</td>\n",
       "      <td>Mycosis fungoides and Sézary syndrome are prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SUCLA2</td>\n",
       "      <td>G118R</td>\n",
       "      <td>Regulated progression through the cell cycle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BRAF</td>\n",
       "      <td>T599insTT</td>\n",
       "      <td>Pilocytic astrocytoma (PA) is emerging as a tu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  \\\n",
       "0   1   CHEK2                 H371Y   \n",
       "1   2   AXIN2  Truncating Mutations   \n",
       "2   3    WNT4                 E216G   \n",
       "3   4  SUCLA2                 G118R   \n",
       "4   5    BRAF             T599insTT   \n",
       "\n",
       "                                                Text  \n",
       "0  The incidence of breast cancer is increasing i...  \n",
       "1  An unselected series of 310 colorectal carcino...  \n",
       "2  Mycosis fungoides and Sézary syndrome are prim...  \n",
       "3   Regulated progression through the cell cycle ...  \n",
       "4  Pilocytic astrocytoma (PA) is emerging as a tu...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_testx = pd.read_csv('../utils/stage2_data/stage2_test_text.csv', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "stage2_test = pd.read_csv('/mnt/4_TB_HD/ramona/utils/stage2_data/stage2_test_variants.csv')\n",
    "stage2_solution = pd.read_csv('../utils/stage2_data/stage_2_private_solution.csv')\n",
    "stage2_merge_df= pd.merge(stage2_test, stage2_testx, how='left', on='ID').fillna('')\n",
    "\n",
    "stage2= pd.merge(stage2_test, stage2_testx, how='left', on='ID').fillna('')\n",
    "stage2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransDict_from_list(groups):\n",
    "        '''\n",
    "        Given a list of letter groups, returns a dict mapping each group to a\n",
    "        single letter from the group - for use in translation.\n",
    "        >>> alex6=[\"C\", \"G\", \"P\", \"FYW\", \"AVILM\", \"STNQRHKDE\"]\n",
    "        >>> trans_a6 = TransDict_from_list(alex6)\n",
    "        >>> print(trans_a6)\n",
    "        {'V': 'A', 'W': 'F', 'T': 'D', 'R': 'D', 'S': 'D', 'P': 'P',\n",
    "         'Q': 'D', 'Y': 'F', 'F': 'F',\n",
    "         'G': 'G', 'D': 'D', 'E': 'D', 'C': 'C', 'A': 'A',\n",
    "          'N': 'D', 'L': 'A', 'M': 'A', 'K': 'D', 'H': 'D', 'I': 'A'}\n",
    "        '''\n",
    "        transDict = dict()\n",
    "\n",
    "        result = {}\n",
    "        for group in groups:\n",
    "            g_members = sorted(group) #Alphabetically sorted list\n",
    "            for c in g_members:\n",
    "                result[c] = str(g_members[0]) #K:V map, use group's first letter as represent.\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finddistance(AA1 = None, AA2=None):\n",
    "        if AA1 in pc5 and AA2 in pc5 and AA1 != 'W':\n",
    "            AAlist = ph_distances.loc[AA1] #Finds row for AA1\n",
    "        else:\n",
    "            return float('nan')\n",
    "        if AA2 == 'S' or AA1=='W':\n",
    "            dist=float('nan')\n",
    "        else:\n",
    "            dist=AAlist.get(AA2) #Search for AA2\n",
    "        if math.isnan(dist): #If not found, switch order and search again\n",
    "            dist = finddistance(AA1=AA2, AA2=AA1)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3573\n",
      "3392\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat((train, stage2), axis=0, ignore_index=True)\n",
    "df_all['Gene_Share'] = df_all.apply(lambda r: sum([1 for w in r['Gene'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n",
    "df_all['Variation_Share'] = df_all.apply(lambda r: sum([1 for w in r['Variation'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n",
    "\n",
    "\n",
    "gen_var_lst = sorted(list(train.Gene.unique()) + list(train.Variation.unique()))\n",
    "print(len(gen_var_lst))\n",
    "gen_var_lst = [x for x in gen_var_lst if len(x.split(' '))==1]\n",
    "print(len(gen_var_lst))\n",
    "i_ = 0\n",
    "\n",
    "\n",
    "df_all[\"simple_variation_pattern\"] = df_all.Variation.str.contains(r'^[A-Z]\\d{1,7}[A-Z]$',case=False)\n",
    "df_all['location_number'] = df_all.Variation.str.extract('(\\d+)', expand=True)\n",
    "AA_VALID = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "df_all['variant_letter_first'] = df_all.apply(lambda row: row.Variation[0] if row.Variation[0] in (AA_VALID) else np.NaN,axis=1)\n",
    "df_all['variant_letter_last'] = df_all.apply(lambda row: row.Variation.split()[0][-1] if (row.Variation.split()[0][-1] in (AA_VALID)) else np.NaN,axis=1)\n",
    "df_all.loc[df_all.simple_variation_pattern==False,['variant_letter_last',\"variant_letter_first\"]] = np.NaN\n",
    "ofer8=TransDict_from_list([\"C\", \"G\", \"P\", \"FYW\", \"AVILM\", \"RKH\", \"DE\", \"STNQ\"])\n",
    "sdm12 =TransDict_from_list([\"A\", \"D\", \"KER\", \"N\",  \"TSQ\", \"YF\", \"LIVM\", \"C\", \"W\", \"H\", \"G\", \"P\"] )\n",
    "pc5 = {\"I\": \"A\", # Aliphatic\n",
    "             \"V\": \"A\",         \"L\": \"A\",\n",
    "             \"F\": \"R\", # Aromatic\n",
    "             \"Y\": \"R\",         \"W\": \"R\",         \"H\": \"R\",\n",
    "             \"K\": \"C\", # Charged\n",
    "             \"R\": \"C\",         \"D\": \"C\",         \"E\": \"C\",\n",
    "             \"G\": \"T\", # Tiny\n",
    "             \"A\": \"T\",         \"C\": \"T\",         \"S\": \"T\",\n",
    "             \"T\": \"D\", # Diverse\n",
    "             \"M\": \"D\",         \"Q\": \"D\",         \"N\": \"D\",\n",
    "             \"P\": \"D\"}\n",
    "#df_all['AAGroup_ofer8_letter_first'] = df_all[\"variant_letter_first\"].map(ofer8)\n",
    "#df_all['AAGroup_ofer8_letter_last'] = df_all[\"variant_letter_last\"].map(ofer8)\n",
    "#df_all['AAGroup_ofer8_equiv'] = df_all['AAGroup_ofer8_letter_first'] == df_all['AAGroup_ofer8_letter_last']\n",
    "#df_all['AAGroup_m12_equiv'] = df_all['variant_letter_last'].map(sdm12) == df_all['variant_letter_first'].map(sdm12)\n",
    "#df_all['AAGroup_p5_equiv'] = df_all['variant_letter_last'].map(pc5) == df_all['variant_letter_first'].map(pc5)\n",
    "\n",
    "\n",
    "\n",
    "ph_distances = pd.read_csv(\"../utils/physiochem.csv\", sep=';')\n",
    "ph_distances = ph_distances.set_index('Unnamed: 0')\n",
    "PC_distance= df_all[['variant_letter_first', 'variant_letter_last']].apply(lambda x: finddistance(x[0],x[1]), axis=1)\n",
    "meanv=np.mean(PC_distance)\n",
    "PC_distance[np.isnan(PC_distance)]=meanv\n",
    "df_all['PC_distance'] = normalize(PC_distance.values.reshape(-1, 1), axis=0)\n",
    "df_all = df_all.drop([\"simple_variation_pattern\",'location_number', 'variant_letter_first','variant_letter_last' ], axis=1,)  \n",
    "df_all = df_all.astype(str)\n",
    "\n",
    "\n",
    "for c in df_all.columns:\n",
    "    if df_all[c].dtype == 'object':\n",
    "        if c in ['Gene','Variation']:\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            df_all[c+'_lbl_enc'] = lbl.fit_transform(df_all[c].values)  \n",
    "            df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n",
    "            df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' ')))\n",
    "        elif c != 'Text' and c != 'PC_distance':\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            df_all[c] = lbl.fit_transform(df_all[c].values)\n",
    "        if c=='Text': \n",
    "            df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n",
    "            df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' '))) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class cust_regression_vals(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        x = x.drop(['Gene', 'Variation','ID','Text'],axis=1).values\n",
    "        return x\n",
    "\n",
    "class cust_txt_col(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        return x[self.key].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3683, 15)\n",
      "(986, 15)\n"
     ]
    }
   ],
   "source": [
    "train = df_all.iloc[:len(train)]; print(train.shape)  \n",
    "test = df_all.iloc[len(train):]; print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline...\n"
     ]
    }
   ],
   "source": [
    "print('Pipeline...')\n",
    "fp = pipeline.Pipeline([\n",
    "    ('union', pipeline.FeatureUnion(\n",
    "        n_jobs = 1,\n",
    "        transformer_list = [\n",
    "            ('standard', cust_regression_vals()),\n",
    "            ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd1', decomposition.TruncatedSVD(n_components=25, n_iter=25, random_state=12))])),\n",
    "            ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd2', decomposition.TruncatedSVD(n_components=25, n_iter=25, random_state=12))])),\n",
    "\n",
    "            ('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), ('tfidf_Text', feature_extraction.text.TfidfVectorizer(preprocessor=ourPreprocessor.myPreprocessor, tokenizer=ourPreprocessor.tokenizeratleastthree, ngram_range=(1,3), stop_words=ourPreprocessor.stopWords, min_df=1)), ('tsvd3', decomposition.TruncatedSVD(n_components=50, n_iter=50, random_state=12))]))\n",
    "        ])\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3683, 111)\n",
      "(986, 111)\n",
      "CPU times: user 1h 13min 46s, sys: 16min 37s, total: 1h 30min 23s\n",
      "Wall time: 47min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_transformed = fp.fit_transform(train)\n",
    "print(train_transformed.shape)\n",
    "test_transformed = fp.transform(test)\n",
    "print(test_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18-05-31-12-21'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pipeline( model=None, time=None):\n",
    "    pickle.dump(fp, open('/mnt/4_TB_HD/ramona/utils/textPipelines/featurepipeline_'+time+'.pkl', 'wb'))\n",
    "    \n",
    "def save_pipelineinfo( model = '' , trainpickle = '', testpickle= '', Y_train='', Y_test='', balance = '', genecolumns='', shuffled = '', svd_name = '', pipeline_date =''):\n",
    "    filename = '/mnt/4_TB_HD/ramona/deliver/pipelineinfo2.csv'\n",
    "    with open(filename,'a') as f:\n",
    "        f = csv.writer(f)\n",
    "        f.writerow([ model, trainpickle, testpickle, Y_train, Y_test, 'full' ,balance,shuffled, genecolumns, svd_name, pipeline_date ])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/4_TB_HD/ramona/utils/features/'\n",
    "filename1 = 'Xtrain_' + time\n",
    "filename2 = 'Xtest_' + time\n",
    "filename3 =  'Ytrain_' + time \n",
    "filename4 =  'Ytest_' + time \n",
    "with open(path + filename1, 'wb') as f1:\n",
    "    pickle.dump(train_transformed, f1)\n",
    "with open(path + filename2, 'wb') as f2:\n",
    "    pickle.dump(test_transformed ,f2)\n",
    "\n",
    "Y_test_stage2_class = pd.read_pickle('../utils/stage2_data/stage2test_classes.sav')['Class'].values\n",
    "with open(path + filename3, 'wb') as f2:\n",
    "    pickle.dump(y ,f2)\n",
    "with open(path + filename4, 'wb') as f2:\n",
    "    pickle.dump(Y_test_stage2_class ,f2)\n",
    "\n",
    "filename5 = 'train_before_pipeline' + time\n",
    "filename6 = 'test_before_pipeline' + time\n",
    "with open(path + filename5, 'wb') as f1:\n",
    "    pickle.dump(train, f1)\n",
    "with open(path + filename6, 'wb') as f2:\n",
    "    pickle.dump(test ,f2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_pipelineinfo([fp.named_steps['union'].transformer_list[0], fp.named_steps['union'].transformer_list[1][1].named_steps, fp.named_steps['union'].transformer_list[2][1].named_steps, fp.named_steps['union'].transformer_list[3][1].named_steps], filename1, filename2, filename3, filename4, shuffled = False,  balance = '', pipeline_date=time)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pipeline(fp, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open('/mnt/4_TB_HD/ramona/utils/textPipelines/featurepipeline_'+time+'.pkl', 'rb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gene': cust_txt_col(key='Gene'),\n",
       " 'count_Gene': CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 8), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None, vocabulary=None),\n",
       " 'tsvd1': TruncatedSVD(algorithm='randomized', n_components=25, n_iter=25,\n",
       "        random_state=12, tol=0.0)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.named_steps['union'].transformer_list[1][1].named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
